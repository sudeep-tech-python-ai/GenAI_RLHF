{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with langchain and OpenAI\n",
    "\n",
    "In this quickstart we'll see how to :\n",
    "* Get setup with langchain,langsmith and langserve\n",
    "* Use the most basic and common components of langchain: prompt templates,models, and output\n",
    "* Build a simple application with langchain\n",
    "* Trace your application with langsmith\n",
    "* Serve your application with langserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x11f5993d0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x12927e8d0> root_client=<openai.OpenAI object at 0x12927df40> root_async_client=<openai.AsyncOpenAI object at 0x118c8fb90> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model='gpt-4o')\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response from LLM\n",
    "result=llm.invoke('What is generative AI?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a category of artificial intelligence systems designed to generate new content. This can include text, images, music, code, and more, based on the patterns and examples it has been trained on. Unlike traditional AI, which often focuses on classification and prediction, generative AI focuses on creation.\n",
      "\n",
      "Generative AI models, such as generative adversarial networks (GANs), variational autoencoders (VAEs), and transformer models like GPT (Generative Pre-trained Transformer), learn from vast datasets and can then create new, original pieces that mimic the properties of the data they were trained on. For instance, GPT-3, a transformer-based model, can generate coherent and contextually relevant text given a prompt, while GANs can produce realistic images from noise.\n",
      "\n",
      "These AI systems have a wide range of applications across different industries:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create articles, blogs, and summarize information.\n",
      "2. **Art and Design**: It can generate artwork or design ideas, helping artists and designers with inspiration.\n",
      "3. **Music Composition**: AI models can compose music that follows specific styles or genres.\n",
      "4. **Speech Synthesis**: It can be used to generate human-like speech for virtual assistants.\n",
      "5. **Code Generation**: AI can assist in writing code snippets or full programs.\n",
      "6. **Data Augmentation**: In machine learning, generative models can create synthetic datasets to improve the training of other models.\n",
      "\n",
      "The technological advancement in generative AI poses both exciting opportunities and significant challenges, such as addressing ethical concerns related to the authenticity of generated content, potential misuse, and the societal impact of AI-generated media.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','you are an expert AI Engineer. Provide me answers based on the question'),\n",
    "        ('user','{input}')\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform or toolkit developed by LangChain that is designed to assist developers in building, debugging, and monitoring applications that utilize Large Language Models (LLMs). It focuses on providing tools that help in understanding and optimizing how LLMs are used within applications, offering features such as:\n",
      "\n",
      "1. **Application Tracing**: This allows developers to log and trace the series of steps an LLM application takes from input to output. This feature is crucial for understanding the decision-making process of the model and debugging any issues that arise during deployment.\n",
      "\n",
      "2. **Performance Monitoring**: LangSmith can monitor the performance of LLM applications, providing insights into how efficiently the model operates, its response times, and resource utilization, which are valuable for optimization.\n",
      "\n",
      "3. **Evaluation and Testing**: The platform provides tools to evaluate the effectiveness of LLM applications, enabling developers to test various scenarios and edge cases to ensure robust output.\n",
      "\n",
      "4. **Debugging Tools**: LangSmith offers tools to aid in identifying bottlenecks, errors, or unexpected behavior in LLM applications, thus speeding up the debugging process.\n",
      "\n",
      "Overall, LangSmith is aimed at making it easier for developers to integrate and maintain LLMs in their software solutions, enhancing the reliability and efficiency of their applications.\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|llm\n",
    "response=chain.invoke({'input':\"can you tell me about langsmith?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform and toolset designed to enhance the development and deployment of applications that utilize large language models (LLMs) and AI chains. It provides developers with capabilities for tracing, monitoring, evaluating, and managing LLM-powered applications to ensure better performance, reliability, and user experience.\n",
      "\n",
      "Key features of Langsmith typically include:\n",
      "\n",
      "1. **Tracing and Monitoring**: Langsmith allows developers to trace the operations within language model applications, enabling them to monitor the inputs, outputs, and interactions within AI workflows. This helps in identifying bottlenecks or issues in the application process.\n",
      "\n",
      "2. **Evaluation Tools**: The platform offers tools for evaluating the effectiveness and efficiency of language models, providing insights into their performance and helping in refining their outputs for desired results.\n",
      "\n",
      "3. **Debugging and Testing**: Langsmith helps developers debug applications by offering a detailed view of the applicationâ€™s behavior and performance under different scenarios. This facilitates effective testing and troubleshooting.\n",
      "\n",
      "4. **Integration Capabilities**: It provides seamless integration with various language models and AI services, allowing developers to easily incorporate advanced language processing capabilities into their applications.\n",
      "\n",
      "5. **Scalability**: Langsmith is designed to support scaling from development to production environments, enabling applications to handle increasing loads and more complex operations as needed.\n",
      "\n",
      "Overall, Langsmith is particularly useful for developers working with complex AI systems and language models, as it helps streamline the development process, optimize application performance, and improve the overall quality of AI-driven solutions.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({'input':'Can you tell me about Langsmith?'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
