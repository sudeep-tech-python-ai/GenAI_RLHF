import streamlit as st 
from langchain_groq import ChatGroq
from langchain.chains import LLMMathChain, LLMChain 
from langchain.prompts import PromptTemplate 
from langchain_community.utilities import WikipediaAPIWrapper
from langchain.agents import Tool, initialize_agent,AgentType
from langchain.callbacks import StreamlitCallbackHandler
from dotenv import load_dotenv
import os 
load_dotenv()
## set up streamlit app 
st.set_page_config(page_title="Text To Math Problem Solver and Data Search Assistant")

st.title("Text to Math Problem Solver using Google Gemma 2")

groq_api_key=st.sidebar.text_input(label="Groq API Key",type="password")

# groq_api_key=os.getenv('GROQ_API_KEY')
if not groq_api_key:
    st.info("Please add your Groq API Key to continue")
    st.stop()

llm=ChatGroq(model="Gemma2-9b-It",groq_api_key=groq_api_key)

## Initializing the tools 
wikipedia_wrapper=WikipediaAPIWrapper(top_k_results=2,doc_content_chars_max=4000)
wikipedia_tool=Tool(
    name='Wikipedia',
    func=wikipedia_wrapper.run,
    description="A tool for searching the Internet to find the various information on the topic mentioned."
)

## Initialize the MATH Tool
math_chain=LLMMathChain.from_llm(llm=llm)
calculate=Tool(
    name="Calculator",
    func=math_chain.run,
    description="A tools for answering math related questions. Only input mathematical expression need  to be provided"
)

prompt="""
Your a agent tasked for solving users mathematical question. Logically arrive at the solution and provide detailed explaination and 
display it point wise for the question below
Question:{question}
Answer:
"""
prompt_template=PromptTemplate(
    input_variables=['question'],
    template=prompt
)

## Combine all the tools into chain 
chain=LLMChain(llm=llm,prompt=prompt_template) 
reasoning_tool=Tool(
    name="Reasoning",
    func=chain.run,
    description="Tool for answering logic-based and reasoning questions."
)

## Initialize the agents 
assistant_agent=initialize_agent(
    tools=[wikipedia_tool,calculate,reasoning_tool],
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=False,
    handle_parsing_errors=True
)

if "messages" not in st.session_state:
    st.session_state["messages"]=[
        {"role":"assistant","content":"Hi, I'm a Math chatbot who can answer all your maths questions"}
    ]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

question=st.text_area("Enter your question","I have 5 bananas and 7 grapes. I eat 2 bananas and give away 3 grapes. Then I buy a dozen apples and 2 packs of blueberries. Each pack of blueberries contains 25 berries. How many total pieces of fruit do I have at the end?")
## Lets start the interaction 
if st.button("find my answer"):
    if question:
        with st.spinner("Generate Response.."):
            st.session_state.messages.append({"role":"user","content":question})
            st.chat_message("user").write(question)

            st_cb=StreamlitCallbackHandler(st.container(),expand_new_thoughts=False)
            response=assistant_agent.run(st.session_state.messages,callbacks=[st_cb])

            st.session_state.messages.append({'role':'assistant','content':response})
            st.write('### Response:')
            st.success(response)
    else:
        st.warning("Please enter the question")